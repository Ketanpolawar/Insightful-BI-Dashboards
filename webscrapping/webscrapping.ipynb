{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: url se data lao html mai convert karo \n",
    "import urllib.request as urllib2#to render data from url\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://en.wikipedia.org/wiki/Global_Internet_usage'\n",
    "res_obj=urllib2.urlopen(url)#response object\n",
    "html_res=res_obj.readlines()\n",
    "res_obj.close()\n",
    "html_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2: html vale lines ko as per need sort karo,table title dhundo\n",
    "import re #library used to search,use regex\n",
    "lst=[]\n",
    "for lines in html_res:\n",
    "  lines=str(lines,'UTF-8').strip()\n",
    "  if re.search('table class',lines):\n",
    "    lst.append(lines)\n",
    "print(type(lst[0]))\n",
    "lst\n",
    "(len(lst))\n",
    "#(lst)\n",
    "#usually table tite is some part  on index 0\n",
    "table_title=re.search('\"([^\"]*)\"',lst[4])\n",
    "table_tit=table_title.group(1)#group one imp\n",
    "table_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3:parsing the data \n",
    "res_obj=urllib2.urlopen(url)#response object\n",
    "htmlpage_as_text=res_obj.read()\n",
    "HCE=BeautifulSoup(htmlpage_as_text)\n",
    "#htmlparser\n",
    "#html5lib\n",
    "res_obj.close()\n",
    "len(HCE.contents)\n",
    "HCE.contents[0]\n",
    "HCE.contents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4:getting data ie table header rows  from table_title\n",
    "table=HCE.find('table',attrs={'class':table_title.group(1)})\n",
    "type(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_headers=[x.text for x in table.find_all('th')]\n",
    "table_row=[x.text for x in table.find_all('tr')]#.text se baki tags aur html ka unwanted data nikal diye hai\n",
    "rows=[]\n",
    "for table_row in table.find_all('tr'):\n",
    "  rows.append([data.text for data in table_row.find_all('td')])\n",
    "rows\n",
    "table_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step5:constructing the dataframe\n",
    "import pandas#constructing dataframe (dono with text wale)\n",
    "df1=pandas.DataFrame(rows,columns=table_headers)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean dataframe\n",
    "def prepoc(dat):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    dat.columns = dat.columns.str.replace('\\n', '')#axis zero vertically downwards\n",
    "    dat.dropna(axis=0,how='all',inplace=True)#minimum kitne ho the delete karna hai (how) # inplace is used to retain the output in original dataframe or use x=xcondituon .\n",
    "    dat.replace(['\\n'],[''],inplace=True,regex=True)# replacing the /n with space [] bracket batahai ki particular chiz ko lena hai aur replace karna hai nahi tho pura hoga replace\n",
    "    dat.replace(['\\s\\*$'],[''],inplace=True,regex=True)#end ki space hata diya\n",
    "    dat.replace(['^\\s'],[''],inplace=True,regex=True)#start ki space hata diya\n",
    "    dat.replace([','],[''],inplace=True,regex=True)#bichme k commas hatadega\n",
    "    dat.replace(r'\\b[a-zA-Z]\\b',np.nan,inplace=True,regex=True)\n",
    "    dat=dat.apply(pd.to_numeric,errors='ignore')#.apply se har colums pr apply hoga voh function\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=prepoc(df1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(r'C:\\Users\\DHANSHRI\\OneDrive\\Desktop\\Acedemics\\dhlv\\ext.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "univarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the labraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt #\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data and forming dataframe as Dfa\n",
    "#Dfa is object or dataframe constructed though pandas\n",
    "Dfa=pd.read_csv('ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfa.head(5)\n",
    "#reading first five lines of dataframe using head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfa.tail(5)\n",
    "# reading last five lines of dataframe using tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfa.shape#returns the dege=ree and cardinality of data using shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfa.info()\n",
    "#gives the info about the datatype no of colums and their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfa.describe()\n",
    "#returns all the mathematical analysis of the data.\n",
    "# method is used to view some basic statistical details like percentile, mean, std, etc. of a data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns numerical features\n",
    "numerical_columns=list(Dfa._get_numeric_data().columns)\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the categeriocal features  of dataframe \n",
    "# Categorical data is non-numerical information that is divided into groups.\n",
    "categeriocal_columns=list(set(Dfa.columns)-set(Dfa._get_numeric_data().columns))\n",
    "categeriocal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab=pd.crosstab(index=Dfa[\"2007\"],columns=Dfa[\"2010\"])\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab.plot(kind=\"bar\",figsize=(12,8),stacked=True,colormap='Paired')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
